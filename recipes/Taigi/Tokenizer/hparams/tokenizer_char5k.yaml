dataset_folder: /mnt/md0/user_jamfly/CORPUS/taigi # !PLACEHOLDER
save_folder: /mnt/md0/user_jamfly/sb_data/taigi # !PLACEHOLDER
output_folder: results/tokenizer_char5k
seed: 1234

token_type: unigram # char # ["unigram", "bpe", "char"]
token_output: 5000
character_coverage: 1.0
annotation_read: translation

train_json: !ref <save_folder>/train.json
dev_json: !ref <save_folder>/dev.json
test_json: !ref <save_folder>/test.json


tokenizer: !name:speechbrain.tokenizers.SentencePiece.SentencePiece
  model_dir: !ref <output_folder>
  vocab_size: !ref <token_output>
  annotation_train: !ref <train_json>
  annotation_read: !ref <annotation_read>
  model_type: !ref <token_type> # ["unigram", "bpe", "char"]
  character_coverage: !ref <character_coverage>
  annotation_list_to_check: [!ref <dev_json>, !ref <test_json>] # yamllint disable-line rule:line-length
  annotation_format: json
  bos_id: 1
  eos_id: 2
